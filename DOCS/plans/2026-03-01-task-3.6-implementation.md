# Task 3.6 — Music UI Integration Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Wire `synth-engine.js` and `music-mapper.js` into `dist/index.html` so the grid plays audio — columns = time, rows = pitch, density = velocity, color = instrument channel.

**Architecture:** Both music modules are inlined into the `<script>` block with `export` keywords stripped, matching the pattern used by every other `src/` module in the file. A `playbackMode` state variable (`'frames'` | `'music'`) routes the existing `▶ Play` button and Space key to either frame animation or the synth engine. A `setPlayheadColumn(col)` method is added to `createRenderer()` to draw the live column cursor.

**Tech Stack:** Web Audio API, `createSynthEngine()` (synth-engine.js), `frameToNoteEvents()` (music-mapper.js), Canvas2D overlay, vanilla JS, single HTML file.

---

## Reference Files

- Design doc: `DOCS/plans/2026-03-01-task-3.6-design.md`
- Source to inline: `src/consumers/music/music-mapper.js` (98 lines)
- Source to inline: `src/consumers/music/synth-engine.js` (487 lines)
- Target file: `dist/index.html` (~1780 lines)
- Tests (DO NOT TOUCH): `tests/test-music-mapper.js`, `tests/test-synth-engine.js`, `tests/run-all.js`

Verify tests pass before starting: `node tests/run-all.js` → all green.

---

### Task 1: Add `setPlayheadColumn()` to `createRenderer()`

**Files:**
- Modify: `dist/index.html` — inside `createRenderer()` (around line 440–511)

This is the lowest-risk change. Do it first so the renderer is ready before music is wired.

**Step 1: Locate the renderer state block**

Find this line in `createRenderer()`:
```js
let showGridLines=false,onFrameChange=options.onFrameChange||null;
```

**Step 2: Add playhead state variable after it**

```js
let showGridLines=false,onFrameChange=options.onFrameChange||null;
let _playheadCol=-1;
```

**Step 3: Add `renderPlayhead()` function after `colorDensity()`**

Find the end of `colorDensity()` — it closes with `}`. Add immediately after:
```js
function renderPlayhead(){
  if(_playheadCol<0)return;
  ctx.fillStyle='rgba(0,255,136,0.18)';
  ctx.fillRect(_playheadCol*cellW,0,cellW,canvasEl.height);
}
```

**Step 4: Call `renderPlayhead()` at the end of `render()`**

Find the last line of `render()` — it is:
```js
if(onFrameChange)onFrameChange(currentFrame,frame);
```
Add `renderPlayhead();` immediately before that line:
```js
renderPlayhead();
if(onFrameChange)onFrameChange(currentFrame,frame);
```

**Step 5: Add `setPlayheadColumn` function before the `return` statement**

Find the line that starts the return object:
```js
return{render,next,prev,goTo,
```
Add this function immediately before it:
```js
function setPlayheadColumn(col){_playheadCol=col;render();}
```

**Step 6: Add `setPlayheadColumn` to the returned object**

The return line currently ends with:
```js
get cellSize(){return{w:cellW,h:cellH}}};
```
Add `setPlayheadColumn` to the returned object — change to:
```js
get cellSize(){return{w:cellW,h:cellH}},setPlayheadColumn};
```

**Step 7: Run tests**

```bash
node tests/run-all.js
```
Expected: same pass count as before, 0 failures.

**Step 8: Commit**

```bash
git add dist/index.html
git commit -m "feat: add setPlayheadColumn to canvas renderer"
```

---

### Task 2: Inline `music-mapper.js`

**Files:**
- Read: `src/consumers/music/music-mapper.js`
- Modify: `dist/index.html` — add new inline block after the input system block (~line 636)

**Step 1: Find the insertion point**

Locate this comment in `dist/index.html`:
```js
// ================================================================
// IMAGE IMPORTER (inlined from src/importers/image-importer.js)
// ================================================================
```
The new block goes **immediately before** that comment.

**Step 2: Insert the inlined music-mapper block**

Add this entire block at the insertion point. It is `music-mapper.js` with all `export` keywords removed:

```js
// ================================================================
// MUSIC MAPPER (inlined from src/consumers/music/music-mapper.js)
// ================================================================
const SCALES = {
  chromatic: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],
  major: [0, 2, 4, 5, 7, 9, 11],
  minor: [0, 2, 3, 5, 7, 8, 10],
  pentatonic: [0, 2, 4, 7, 9],
  minor_penta: [0, 3, 5, 7, 10],
  blues: [0, 3, 5, 6, 7, 10],
  dorian: [0, 2, 3, 5, 7, 9, 10],
  mixolydian: [0, 2, 4, 5, 7, 9, 10],
  harmonic_minor: [0, 2, 3, 5, 7, 8, 11],
  whole_tone: [0, 2, 4, 6, 8, 10],
};

const NOTE_NAMES = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];

function midiToFrequency(note) {
  return 440 * Math.pow(2, (note - 69) / 12);
}

function midiToName(note) {
  const octave = Math.floor(note / 12) - 1;
  return NOTE_NAMES[note % 12] + octave;
}

function columnToTime(col, bpm, subdivision) {
  const beatDuration = 60 / bpm;
  const stepDuration = beatDuration / subdivision;
  return col * stepDuration;
}

function rowToNote(row, height, scale, rootNote) {
  const invertedRow = (height - 1) - row;
  const scaleIntervals = SCALES[scale] || SCALES.chromatic;
  const octave = Math.floor(invertedRow / scaleIntervals.length);
  const degree = invertedRow % scaleIntervals.length;
  return rootNote + (octave * 12) + scaleIntervals[degree];
}

function colorToChannel(color) {
  const CHANNEL_MAP = {
    '#ff0000': 0,
    '#00ff00': 1,
    '#0000ff': 2,
    '#ffff00': 3,
    '#ff00ff': 4,
    '#00ffff': 5,
  };
  return CHANNEL_MAP[color?.toLowerCase()] ?? 0;
}

function cellToNoteEvent(cell, gridWidth, gridHeight, musicOpts) {
  if (!cell || cell.semantic === 'void') return null;
  const { bpm = 120, subdivision = 4, scale = 'chromatic', rootNote = 60 } = musicOpts || {};
  return {
    note: Math.min(127, Math.max(0, rowToNote(cell.y, gridHeight, scale, rootNote))),
    velocity: Math.min(127, Math.max(0, cell.channel?.audio?.velocity ?? Math.round((cell.density ?? 0.5) * 127))),
    time: columnToTime(cell.x, bpm, subdivision),
    duration: (cell.channel?.audio?.duration ?? 1) * (60 / bpm / subdivision),
    channel: colorToChannel(cell.color),
    char: cell.char,
  };
}

function frameToNoteEvents(grid, frameIndex, opts) {
  const frame = grid.frames[frameIndex];
  if (!frame) return [];
  const events = [];
  for (const cell of frame.cells) {
    const event = cellToNoteEvent(cell, grid.canvas.width, grid.canvas.height, opts);
    if (event) events.push(event);
  }
  return events.sort((a, b) => a.time - b.time || a.note - b.note);
}
```

**Step 3: Run tests**

```bash
node tests/run-all.js
```
Expected: same pass count, 0 failures. (The test files still import from `src/` — this inline doesn't affect them.)

**Step 4: Commit**

```bash
git add dist/index.html
git commit -m "feat: inline music-mapper into dist/index.html"
```

---

### Task 3: Inline `synth-engine.js`

**Files:**
- Read: `src/consumers/music/synth-engine.js`
- Modify: `dist/index.html` — add new inline block immediately after the music-mapper block

**Step 1: Find the insertion point**

Immediately after the `// ================================================================` comment closing the music-mapper block, before the `// IMAGE IMPORTER` comment.

**Step 2: Insert the inlined synth-engine block**

This is `synth-engine.js` with: (a) the `import` line at the top removed, (b) all `export` keywords stripped from declarations.

```js
// ================================================================
// SYNTH ENGINE (inlined from src/consumers/music/synth-engine.js)
// ================================================================
const INSTRUMENTS = {
    0: { name: 'lead', wave: 'sawtooth', attack: 0.01, decay: 0.1, sustain: 0.7, release: 0.2, filterFreq: 2000 },
    1: { name: 'bass', wave: 'sine', attack: 0.01, decay: 0.2, sustain: 0.8, release: 0.1, filterFreq: 800 },
    2: { name: 'pad', wave: 'triangle', attack: 0.3, decay: 0.3, sustain: 0.6, release: 0.5, filterFreq: 4000 },
    3: { name: 'arp', wave: 'square', attack: 0.005, decay: 0.05, sustain: 0.3, release: 0.05, filterFreq: 3000 },
    4: { name: 'drums', wave: 'noise', attack: 0.001, decay: 0.1, sustain: 0, release: 0.05, filterFreq: 8000 },
    5: { name: 'fx', wave: 'sine', attack: 0.1, decay: 0.5, sustain: 0.3, release: 1.0, filterFreq: 6000 },
};

const MAX_POLYPHONY = 16;

let _noiseBuffer = null;

function createNoiseBuffer(audioCtx) {
    if (_noiseBuffer && _noiseBuffer.sampleRate === audioCtx.sampleRate) return _noiseBuffer;
    const length = 2 * audioCtx.sampleRate;
    const buffer = audioCtx.createBuffer(1, length, audioCtx.sampleRate);
    const data = buffer.getChannelData(0);
    for (let i = 0; i < length; i++) data[i] = Math.random() * 2 - 1;
    _noiseBuffer = buffer;
    return buffer;
}

function _resetNoiseBuffer() { _noiseBuffer = null; }

function applyADSR(gainNode, time, velocity, adsr, duration) {
    const peak = (velocity / 127) * 0.8;
    const sustainLevel = peak * adsr.sustain;
    const releaseEnd = time + duration + adsr.release;
    const gain = gainNode.gain;
    gain.setValueAtTime(0, time);
    gain.linearRampToValueAtTime(peak, time + adsr.attack);
    gain.linearRampToValueAtTime(Math.max(sustainLevel, 0.001), time + adsr.attack + adsr.decay);
    gain.setValueAtTime(Math.max(sustainLevel, 0.001), time + duration);
    gain.exponentialRampToValueAtTime(0.001, releaseEnd);
}

function playTonalNote(audioCtx, destination, event, instrument) {
    const osc = audioCtx.createOscillator();
    osc.type = instrument.wave;
    osc.frequency.setValueAtTime(midiToFrequency(event.note), event.time);
    const filter = audioCtx.createBiquadFilter();
    filter.type = 'lowpass';
    filter.frequency.setValueAtTime(instrument.filterFreq, event.time);
    filter.Q.setValueAtTime(1, event.time);
    const gain = audioCtx.createGain();
    applyADSR(gain, event.time, event.velocity, instrument, event.duration);
    osc.connect(filter);
    filter.connect(gain);
    gain.connect(destination);
    const stopTime = event.time + event.duration + instrument.release + 0.01;
    osc.start(event.time);
    osc.stop(stopTime);
    return { osc, filter, gain, stopTime };
}

function playDrum(audioCtx, destination, event) {
    const v = (event.velocity / 127) * 0.8;
    const time = event.time;
    const nodes = [];
    if (event.note > 80) {
        const buffer = createNoiseBuffer(audioCtx);
        const src = audioCtx.createBufferSource();
        src.buffer = buffer;
        const hp = audioCtx.createBiquadFilter();
        hp.type = 'highpass';
        hp.frequency.setValueAtTime(8000, time);
        const gain = audioCtx.createGain();
        gain.gain.setValueAtTime(v * 0.3, time);
        gain.gain.exponentialRampToValueAtTime(0.001, time + 0.06);
        src.connect(hp); hp.connect(gain); gain.connect(destination);
        src.start(time); src.stop(time + 0.06);
        nodes.push(src, hp, gain);
        return { nodes, stopTime: time + 0.06 };
    } else if (event.note > 50) {
        const buffer = createNoiseBuffer(audioCtx);
        const noiseSrc = audioCtx.createBufferSource();
        noiseSrc.buffer = buffer;
        const bp = audioCtx.createBiquadFilter();
        bp.type = 'bandpass';
        bp.frequency.setValueAtTime(3000, time);
        const noiseGain = audioCtx.createGain();
        noiseGain.gain.setValueAtTime(v * 0.4, time);
        noiseGain.gain.exponentialRampToValueAtTime(0.001, time + 0.12);
        noiseSrc.connect(bp); bp.connect(noiseGain); noiseGain.connect(destination);
        noiseSrc.start(time); noiseSrc.stop(time + 0.12);
        const osc = audioCtx.createOscillator();
        osc.type = 'triangle';
        osc.frequency.setValueAtTime(180, time);
        osc.frequency.exponentialRampToValueAtTime(80, time + 0.07);
        const toneGain = audioCtx.createGain();
        toneGain.gain.setValueAtTime(v * 0.5, time);
        toneGain.gain.exponentialRampToValueAtTime(0.001, time + 0.1);
        osc.connect(toneGain); toneGain.connect(destination);
        osc.start(time); osc.stop(time + 0.12);
        nodes.push(noiseSrc, bp, noiseGain, osc, toneGain);
        return { nodes, stopTime: time + 0.12 };
    } else {
        const osc = audioCtx.createOscillator();
        osc.type = 'sine';
        osc.frequency.setValueAtTime(150, time);
        osc.frequency.exponentialRampToValueAtTime(30, time + 0.15);
        const gain = audioCtx.createGain();
        gain.gain.setValueAtTime(v * 0.8, time);
        gain.gain.exponentialRampToValueAtTime(0.001, time + 0.3);
        osc.connect(gain); gain.connect(destination);
        osc.start(time); osc.stop(time + 0.3);
        nodes.push(osc, gain);
        return { nodes, stopTime: time + 0.3 };
    }
}

function limitPolyphony(events, maxVoices = MAX_POLYPHONY) {
    if (events.length <= maxVoices) return events;
    const byTime = new Map();
    for (const e of events) {
        const key = e.time.toFixed(6);
        if (!byTime.has(key)) byTime.set(key, []);
        byTime.get(key).push(e);
    }
    const result = [];
    for (const [, group] of byTime) {
        if (group.length <= maxVoices) { result.push(...group); }
        else { group.sort((a, b) => b.velocity - a.velocity); result.push(...group.slice(0, maxVoices)); }
    }
    return result.sort((a, b) => a.time - b.time || a.note - b.note);
}

function createSynthEngine(audioCtx) {
    let isPlaying = false;
    let isPaused = false;
    let playStartTime = 0;
    let currentColumn = -1;
    let animFrameId = null;
    let activeNodes = [];
    let instruments = { ...INSTRUMENTS };

    const masterGain = audioCtx.createGain();
    masterGain.gain.setValueAtTime(0.7, audioCtx.currentTime);
    masterGain.connect(audioCtx.destination);

    function clearActiveNodes() {
        for (const node of activeNodes) {
            try {
                if (node.osc) node.osc.disconnect();
                if (node.filter) node.filter.disconnect();
                if (node.gain) node.gain.disconnect();
                if (node.nodes) { for (const n of node.nodes) { try { n.disconnect(); } catch (_) {} } }
            } catch (_) {}
        }
        activeNodes = [];
    }

    function cancelCursorTick() {
        if (animFrameId !== null) {
            if (typeof cancelAnimationFrame === 'function') cancelAnimationFrame(animFrameId);
            animFrameId = null;
        }
    }

    function scheduleFrame(noteEvents, startTime) {
        const limited = limitPolyphony(noteEvents);
        for (const event of limited) {
            const scheduled = { ...event, time: startTime + event.time };
            const inst = instruments[event.channel] ?? instruments[0];
            if (event.channel === 4) { activeNodes.push(playDrum(audioCtx, masterGain, scheduled)); }
            else { activeNodes.push(playTonalNote(audioCtx, masterGain, scheduled, inst)); }
        }
    }

    function play(grid, frameIndex, opts) {
        if (isPlaying) stop();
        const noteEvents = frameToNoteEvents(grid, frameIndex, opts);
        const bpm = opts.bpm || 120;
        const subdivision = opts.subdivision || 4;
        const stepDuration = 60 / bpm / subdivision;
        const gridWidth = grid.canvas?.width || 1;
        playStartTime = audioCtx.currentTime;
        isPlaying = true;
        isPaused = false;
        currentColumn = -1;
        scheduleFrame(noteEvents, playStartTime);
        function tick() {
            if (!isPlaying || isPaused) return;
            const elapsed = audioCtx.currentTime - playStartTime;
            const newCol = Math.floor(elapsed / stepDuration);
            if (newCol !== currentColumn) {
                currentColumn = newCol;
                if (currentColumn >= gridWidth) {
                    if (opts.loop) {
                        currentColumn = 0;
                        clearActiveNodes();
                        playStartTime = audioCtx.currentTime;
                        scheduleFrame(noteEvents, playStartTime);
                    } else { stop(); return; }
                }
                if (typeof opts.onColumnChange === 'function') opts.onColumnChange(currentColumn);
            }
            if (typeof requestAnimationFrame === 'function') animFrameId = requestAnimationFrame(tick);
        }
        if (typeof requestAnimationFrame === 'function') animFrameId = requestAnimationFrame(tick);
    }

    function stop() {
        isPlaying = false;
        isPaused = false;
        currentColumn = -1;
        cancelCursorTick();
        clearActiveNodes();
    }

    function pause() {
        if (!isPlaying || isPaused) return;
        isPaused = true;
        cancelCursorTick();
        if (typeof audioCtx.suspend === 'function') audioCtx.suspend();
    }

    function resume() {
        if (!isPlaying || !isPaused) return;
        isPaused = false;
        if (typeof audioCtx.resume === 'function') audioCtx.resume();
        if (typeof requestAnimationFrame === 'function') {
            animFrameId = requestAnimationFrame(function tick() {
                if (!isPlaying || isPaused) return;
                if (typeof requestAnimationFrame === 'function') animFrameId = requestAnimationFrame(tick);
            });
        }
    }

    function setMasterVolume(v) {
        const clamped = Math.max(0, Math.min(1, v));
        masterGain.gain.setValueAtTime(clamped, audioCtx.currentTime);
    }

    function setInstrument(channel, instrumentDef) {
        instruments[channel] = { ...instruments[channel], ...instrumentDef };
    }

    function destroy() { stop(); masterGain.disconnect(); }

    return {
        scheduleFrame, play, stop, pause, resume, setMasterVolume, setInstrument, destroy,
        get isPlaying() { return isPlaying; },
        get isPaused() { return isPaused; },
        get currentTime() { return isPlaying ? audioCtx.currentTime - playStartTime : 0; },
        get currentColumn() { return currentColumn; },
    };
}
```

**Step 3: Run tests**

```bash
node tests/run-all.js
```
Expected: same pass count, 0 failures.

**Step 4: Commit**

```bash
git add dist/index.html
git commit -m "feat: inline synth-engine into dist/index.html"
```

---

### Task 4: Add music app state variables

**Files:**
- Modify: `dist/index.html` — app state block (~line 872)

**Step 1: Find the app state block**

```js
// ================================================================
// APPLICATION STATE
// ================================================================
let grid = createGrid(...);
let renderer = null;
let inputSystem = null;
let selectedChar = '@';
let selectedColor = '#00ff88';
let eraserMode = false;
```

**Step 2: Add three new state variables after `eraserMode`**

```js
let playbackMode = 'frames';   // 'frames' | 'music'
let audioCtx = null;
let synth = null;
```

**Step 3: Run tests**

```bash
node tests/run-all.js
```
Expected: 0 failures.

**Step 4: Commit**

```bash
git add dist/index.html
git commit -m "feat: add playbackMode, audioCtx, synth to app state"
```

---

### Task 5: Add the mode toggle button to the toolbar

**Files:**
- Modify: `dist/index.html` — toolbar HTML (around line 217)

**Step 1: Find the toolbar playback div**

```html
<div class="playback">
  <button onclick="prevFrameAction()" class="small">◀</button>
  <button onclick="togglePlayback()" class="small" id="playBtn">▶ Play</button>
  <button onclick="nextFrameAction()" class="small">▶</button>
  <button onclick="stopPlayback()" class="small">⏹</button>
</div>
<div class="sep"></div>
```

**Step 2: Add the mode toggle button after the `<div class="sep"></div>` that follows the playback div**

Insert immediately after that first `<div class="sep"></div>`:

```html
<button id="modeToggleBtn" onclick="togglePlaybackMode()" class="small" title="Switch between frame animation and music playback">Frames</button>
<div class="sep"></div>
```

The toolbar will now read: `◀ ▶ Play ▶ ⏹ | Frames | FPS:[10] | ...`

**Step 3: Run tests**

```bash
node tests/run-all.js
```
Expected: 0 failures (HTML change, no JS change yet).

**Step 4: Commit**

```bash
git add dist/index.html
git commit -m "feat: add mode toggle button to toolbar"
```

---

### Task 6: Add music transport functions

**Files:**
- Modify: `dist/index.html` — after `stopPlayback()` / near the PLAYBACK section (~line 1140)

**Step 1: Find the PLAYBACK section**

```js
// ================================================================
// PLAYBACK
// ================================================================
function togglePlayback() { ... }
function stopPlayback() { ... }
function nextFrameAction() { ... }
```

**Step 2: Add four new functions immediately after `stopPlayback()`**

```js
// ----------------------------------------------------------------
// MUSIC TRANSPORT
// ----------------------------------------------------------------
function keyToMidi(key) {
  const map = { C:60,'C#':61,D:62,'D#':63,E:64,F:65,'F#':66,G:67,'G#':68,A:69,'A#':70,B:71 };
  return map[key] ?? 60;
}

function toggleMusicPlayback() {
  if (!audioCtx) {
    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    synth = createSynthEngine(audioCtx);
  }
  if (audioCtx.state === 'suspended') audioCtx.resume();
  if (synth.isPlaying) {
    synth.pause();
    document.getElementById('playBtn').textContent = '▶ Play';
    return;
  }
  const bpm = grid.project.bpm || 120;
  const scale = grid.project.scale || 'chromatic';
  synth.play(grid, renderer.current, {
    bpm,
    scale,
    rootNote: keyToMidi(grid.project.key || 'C'),
    subdivision: 4,
    loop: true,
    onColumnChange(col) { renderer.setPlayheadColumn(col); },
  });
  document.getElementById('playBtn').textContent = '⏸ Pause';
  setStatus(`Playing — ${bpm} BPM, ${scale}`);
}

function stopMusicPlayback() {
  if (synth) synth.stop();
  renderer.setPlayheadColumn(-1);
  document.getElementById('playBtn').textContent = '▶ Play';
  setStatus('Stopped');
}

function togglePlaybackMode() {
  // Stop whatever is currently playing
  if (playbackMode === 'frames') { renderer.stop(); document.getElementById('playBtn').textContent = '▶ Play'; }
  else { stopMusicPlayback(); }
  // Flip mode
  playbackMode = playbackMode === 'frames' ? 'music' : 'frames';
  const btn = document.getElementById('modeToggleBtn');
  btn.textContent = playbackMode === 'music' ? 'Music' : 'Frames';
  btn.className = playbackMode === 'music' ? 'small active' : 'small';
  setStatus(`Mode: ${playbackMode}`);
}
```

**Step 3: Run tests**

```bash
node tests/run-all.js
```
Expected: 0 failures.

**Step 4: Commit**

```bash
git add dist/index.html
git commit -m "feat: add music transport functions — toggleMusicPlayback, stopMusicPlayback, togglePlaybackMode"
```

---

### Task 7: Update `togglePlayback()` and `stopPlayback()` to dispatch by mode

**Files:**
- Modify: `dist/index.html` — existing `togglePlayback()` and `stopPlayback()`

**Step 1: Find the existing functions**

```js
function togglePlayback() {
  const playing = renderer.toggle();
  document.getElementById('playBtn').textContent = playing ? '⏸ Pause' : '▶ Play';
}
function stopPlayback() { renderer.stop(); document.getElementById('playBtn').textContent = '▶ Play'; updateUI(); }
```

**Step 2: Replace with dispatch versions**

```js
function togglePlayback() {
  if (playbackMode === 'music') { toggleMusicPlayback(); return; }
  const playing = renderer.toggle();
  document.getElementById('playBtn').textContent = playing ? '⏸ Pause' : '▶ Play';
}
function stopPlayback() {
  if (playbackMode === 'music') { stopMusicPlayback(); return; }
  renderer.stop();
  document.getElementById('playBtn').textContent = '▶ Play';
  updateUI();
}
```

**Step 3: Run tests**

```bash
node tests/run-all.js
```
Expected: 0 failures.

**Step 4: Commit**

```bash
git add dist/index.html
git commit -m "feat: dispatch togglePlayback/stopPlayback by playbackMode"
```

---

### Task 8: Cleanup on new project / grid load

**Files:**
- Modify: `dist/index.html` — `loadGridIntoApp()` and `createNewProject()`

**Step 1: Find `loadGridIntoApp()`**

Search for `function loadGridIntoApp(`. It loads a new grid into the renderer and rebuilds UI.

**Step 2: Add cleanup at the top of `loadGridIntoApp()`**

After the opening `{` of `loadGridIntoApp`, add:

```js
if (synth) { synth.stop(); synth = null; }
if (audioCtx) { audioCtx.close(); audioCtx = null; }
if (renderer) renderer.setPlayheadColumn(-1);
```

**Step 3: Find `createNewProject()`**

Search for `function createNewProject(`. It creates a fresh grid and calls `loadGridIntoApp` or similar.

**Step 4: Verify cleanup path**

If `createNewProject()` calls `loadGridIntoApp()` internally, the cleanup in step 2 already covers it. Check — if it does NOT call `loadGridIntoApp()`, add the same three cleanup lines to the top of `createNewProject()` as well.

**Step 5: Run tests**

```bash
node tests/run-all.js
```
Expected: 0 failures.

**Step 6: Commit**

```bash
git add dist/index.html
git commit -m "feat: cleanup audioCtx and synth on new project / grid load"
```

---

### Task 9: Browser verification

No tests to write — this is the manual smoke test.

**Step 1: Open `dist/index.html` in Chrome/Edge**

`file:///E:/co/GRID/dist/index.html`

**Step 2: Verify mode toggle**

- Toolbar shows "Frames" button (not active-styled initially — it shows the other mode)
- Click it → button reads "Music", status bar reads "Mode: music"
- Click again → back to "Frames"

**Step 3: Verify music playback with a generator**

1. Switch to Music mode (click toggle until it reads "Music")
2. Click "Terrain" generator to fill the grid
3. Press Space or click ▶ Play
4. You should hear audio (may need headphones to confirm) and see a translucent green vertical bar scanning left-to-right across the canvas
5. The playhead bar advances one column per sixteenth note at 120 BPM
6. After reaching the last column, it loops back to 0
7. Click ⏹ Stop → bar disappears, button resets to ▶ Play

**Step 4: Verify frame mode still works**

1. Click mode toggle → "Frames"
2. Press Space → frame animation plays (advances frames)
3. Press Space again → pauses

**Step 5: Verify Space key dispatches correctly in each mode**

1. Frames mode: Space toggles frame animation
2. Music mode: Space toggles audio playback

**Step 6: Verify BPM/scale respected**

1. Open Project Settings (Ctrl+,)
2. Change BPM to 60
3. Start music playback
4. Playhead should advance at half the speed of 120 BPM

**Step 7: Verify cleanup on new project**

1. Start music playback
2. Press Ctrl+N → new project dialog → Create
3. Audio stops, playhead cleared, no crashes

**Step 8: Run final test suite**

```bash
node tests/run-all.js
```
Expected: same pass count as before Task 1, 0 failures.

**Step 9: Final commit**

```bash
git add dist/index.html
git commit -m "feat: Task 3.6 complete — music UI integration

Grid plays audio. Columns = time, rows = pitch, density = velocity,
color = channel. playbackMode toggle in toolbar routes Space/Play to
frame animation or synth engine. setPlayheadColumn cursor overlay.
BPM/scale/key from project.grid settings. Loop on by default.

Co-Authored-By: Claude Sonnet 4.6 <noreply@anthropic.com>"
```

---

## Quick Reference: Exact Strings to Find

| What | Search string |
|------|--------------|
| Renderer state line | `let showGridLines=false,onFrameChange` |
| After `colorDensity` fn | `function render(fi){` |
| End of `render()` | `if(onFrameChange)onFrameChange(currentFrame,frame)` |
| Return object start | `return{render,next,prev,goTo,` |
| Return object end | `get cellSize(){return{w:cellW,h:cellH}}};` |
| Insertion point (inlines) | `// IMAGE IMPORTER (inlined` |
| App state block | `// APPLICATION STATE` |
| Playback section | `// PLAYBACK` |
| Existing togglePlayback | `function togglePlayback() {` |
| Existing stopPlayback | `function stopPlayback()` |
| loadGridIntoApp | `function loadGridIntoApp(` |
| createNewProject | `function createNewProject(` |
